<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Alexczar E. Dela Torre | Projects</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Rock+Salt&family=Spline+Sans&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.7.2/font/bootstrap-icons.css">
    <link rel="stylesheet" href="css/default.css">
    <link rel="stylesheet" href="css/projects.css">
</head>

<body>
    <header>
        <div class="navbar">
            <a class="logo" href="index.html">Alex Dela Torre</a>
            <nav>
                <ul>
                    <li>
                        <a class="nav-item" href="cv.html">CV</a>
                    </li>
                    <li>
                        <a class="nav-item" href="projects.html">PROJECTS</a>
                    </li>
                </ul>
            </nav>
        </div>
    </header>
    <div class="content">
        <h1 class="content-title">Projects</h1>
        <div class="project">
            <h2 class="content-subtitle">Train and Crowd Simulation
                <a href="https://github.com/dlsucomet/trainsim"><span class="bi bi-github"></span></a>
                <a href="files/tracs-technical-paper.pdf"><span class="bi bi-file-earmark-pdf-fill"></span></a>
            </h2>
            <div class="project-video-container">
                <video class="project-video" height="auto" controls>
                    <source src="assets/videos/tracs-demo.mp4" type="video/mp4">
                    Sorry, your browser does not support the &lt;video&gt; tag.
                </video>
            </div>
            <div class="project-video-caption">
                A demonstration of the train and crowd simulation featuring the platforms of the Santolan station of the
                LRT-2 line. Passengers are seen to wait for a train on the platform. More passengers are seen alighting
                from a train at the beginning (0:02). A view of the Santolan station concourse is then seen (0:08) with
                passengers lining up for the security gate, ticket booths, and turnstiles. The alighting passengers
                coming from the upper floor are seen to descend from the stairs and escalators. As the view returns to
                the platforms (0:18), passengers are seen to board a train towards the end of the video (0:28).
            </div>
            <p class="project-video-description">
                I am currently working on an agent-based model of Metro Manila's three rapid transit train systems
                (LRT-1, LRT-2, and MRT-3). The model <strong>comprehensively and simultaneously</strong> simulates
                both train
                operations and passenger crowds within each train system. The goal of the model is to allow for the
                observation and analysis of how the deployed trains and the passengers as crowds influence each
                other. The model was validated against empirical smart card trip data and video recordings of stations
                to ensure fidelity to the real-world train systems.
                <br>
                <br>
                To support the high level of integration between train and crowd dynamics, numerous
                techniques have been used to optimize the model such as parallelization of agent simulation,
                precomputing of paths and routes, and caching of commonly-computed results. The model is made with Java,
                using JavaFX as the graphical user interface (GUI) framework. The model parameters are stored in an
                SQLite relational database.
                <br>
                <br>
                I started developing this model in December of 2019 for my Master's thesis under the tutelage of <a
                    href="https://unissechua.github.io">
                    Unisse
                    Chua
                </a> and <a href="https://brianesamson.com">Dr. Briane Samson</a> under the <a href="https://comet.dlsu.edu.ph/">Center for Complexity and
                    Emerging Technologies (COMET) laboratory</a>.
                The research has been awarded the
                <strong>gold medal for outstanding thesis</strong> by the College of Computer Studies (CCS) in
                September 2021. In December 2021, I presented this work at the 17th ERDT Conference and has been
                awarded as the <strong><a href="https://www.facebook.com/photo/?fbid=279602774208741">best
                        paper</a></strong> among Information and Communications Technology (ICT) topics. This system
                has since been incorporated with the System for Optimized Routing for
                Transport (SORT) project of the Department of Science and Technology (DOST). As part of the SORT
                team, we plan on extending this model to support even higher and more comprehensive levels of
                integration (such as the simulation of all train systems at once), as well as for the support of
                more transport modes.
                <br>
                <br>
                <strong>GitHub</strong>: <a
                    href="https://github.com/dlsucomet/trainsim">https://github.com/dlsucomet/trainsim</a>
                <br>
                <strong>Technical Paper</strong>: <a href="files/tracs-technical-paper.pdf">Investigating the
                    Interaction Between Crowd Dynamics and Train Operations Through Agent-Based Modeling</a>
            </p>
        </div>
        <div class="project">
            <h2 class="content-subtitle">
                ViTune
                <a href="https://github.com/AlxDt/vitune"><span class="bi bi-github"></span></a>
                <a href="files/vitune-publication.pdf"><span class="bi bi-file-earmark-pdf-fill"></span></a>
            </h2>
            <div class="project-video-container">
                <video class="project-video" controls>
                    <source src="assets/videos/vitune-primer.mp4" type="video/mp4">
                    Sorry, your browser does not support the &lt;video&gt; tag.
                </video>
            </div>
            <div class="project-video-caption">
                A primer for the ViTune project. A short demonstration of the visualizer prototype is shown towards the
                end of the video (0:15). This primer was narrated by Carlo Eroles.
            </div>
            <p class="project-video-description">
                I worked on a prototype for a music visualizer made for the Deaf and Hard of Hearing (DHH) community.
                The system aimed to augment the musical experience of the DHH community through the visualizations
                produced by the prototype. The visualizations were designed according to principles set in related
                literature as well as with direct consultations with the DHH community. The prototype was incrementally
                improved through three iterations.
                <br>
                <br>
                The prototype was made in Python using Django as its framework. Audio processing techniques such as beat
                detection, fast Fourier transforms (FFT), and the use of spectrograms to detect the notes of .wav music
                files were utilized to produce the visualizations.
                <br>
                <br>
                Together with Toei Ciriaco, Carlo Eroles, and Hans Lee, we developed the prototype over the course of a
                year starting October of 2018 and finishing September of 2019 as part of our requirements for a
                Bachelor's degree in Computer Science. We were advised by Jordan Deja under the <a
                    href="https://comet.dlsu.edu.ph/">Center for Complexity and Emerging Technologies (COMET)
                    laboratory</a>. We were in close collaboration with interpreters and the DHH community through the
                <a href="https://www.benilde.edu.ph/academics/sdeas.html">School of Deaf Education and Studies
                    (SDEAS)</a> of the De La Salle - College of Saint Benilde. In April 2020, <a href="https://doi.org/10.1145/3334480.3383046">the tool was featured as part of the Late-Breaking Works for the ACM CHI Conference on Human Factors in Computing Systems Conference</a>.
                <br>
                <br>
                <strong>GitHub</strong>: <a href="https://github.com/AlxDt/vitune">https://github.com/AlxDt/vitune</a>
                <br>
                <strong>Publication</strong>: <a href="files/vitune-publication.pdf">ViTune: A Visualizer Tool to Allow
                    the Deaf and Hard of Hearing to See Music With Their Eyes</a>
            </p>
            <div class="project-video-container">
                <video class="project-video" controls>
                    <source src="assets/videos/vitune-demo.mp4" type="video/mp4">
                    Sorry, your browser does not support the &lt;video&gt; tag.
                </video>
            </div>
            <div class="project-video-caption">
                A demonstration of the prototype visualizing the song <a
                    href="https://www.youtube.com/watch?v=FBrhjrHcWw0">"Komm, s√ºsser Tod" as performed by Jenny</a>. The
                visualization may also include captions of songs with lyrics.
            </div>
        </div>
    </div>
</body>

</html>